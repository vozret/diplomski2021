veronika@kamis-nn01:~/radiIzvanka_QAApproved/probe$ vim proba4.py 
veronika@kamis-nn01:~/radiIzvanka_QAApproved/probe$ python3 proba4.py 
2021-04-06 11:29:35.738554: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-04-06 11:29:35.738598: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-04-06 11:29:38.490216: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-06 11:29:38.493826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-06 11:29:38.539174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-06 11:29:38.539984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:81:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-04-06 11:29:38.540055: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540104: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540143: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540180: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540218: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540253: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540287: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540324: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2021-04-06 11:29:38.540332: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-04-06 11:29:38.540648: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-06 11:29:38.545634: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-06 11:29:38.545663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-06 11:29:38.545680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
img (InputLayer)                [(None, 512, 512, 3) 0                                            
__________________________________________________________________________________________________
separable_conv2d (SeparableConv (None, 512, 512, 16) 91          img[0][0]                        
__________________________________________________________________________________________________
activation (Activation)         (None, 512, 512, 16) 0           separable_conv2d[0][0]           
__________________________________________________________________________________________________
separable_conv2d_1 (SeparableCo (None, 512, 512, 16) 416         activation[0][0]                 
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 16) 0           separable_conv2d_1[0][0]         
__________________________________________________________________________________________________
separable_conv2d_2 (SeparableCo (None, 512, 512, 16) 416         activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 512, 512, 16) 0           separable_conv2d_2[0][0]         
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 256, 256, 16) 0           activation_2[0][0]               
__________________________________________________________________________________________________
separable_conv2d_3 (SeparableCo (None, 256, 256, 32) 688         max_pooling2d[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 32) 0           separable_conv2d_3[0][0]         
__________________________________________________________________________________________________
separable_conv2d_4 (SeparableCo (None, 256, 256, 32) 1344        activation_3[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 32) 0           separable_conv2d_4[0][0]         
__________________________________________________________________________________________________
separable_conv2d_5 (SeparableCo (None, 256, 256, 32) 1344        activation_4[0][0]               
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 32) 0           separable_conv2d_5[0][0]         
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           activation_5[0][0]               
__________________________________________________________________________________________________
separable_conv2d_6 (SeparableCo (None, 128, 128, 64) 2400        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 128, 128, 64) 0           separable_conv2d_6[0][0]         
__________________________________________________________________________________________________
separable_conv2d_7 (SeparableCo (None, 128, 128, 64) 4736        activation_6[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 128, 128, 64) 0           separable_conv2d_7[0][0]         
__________________________________________________________________________________________________
separable_conv2d_8 (SeparableCo (None, 128, 128, 64) 4736        activation_7[0][0]               
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 64) 0           separable_conv2d_8[0][0]         
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_8[0][0]               
__________________________________________________________________________________________________
separable_conv2d_9 (SeparableCo (None, 64, 64, 128)  8896        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 64, 128)  0           separable_conv2d_9[0][0]         
__________________________________________________________________________________________________
separable_conv2d_10 (SeparableC (None, 64, 64, 128)  17664       activation_9[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 64, 64, 128)  0           separable_conv2d_10[0][0]        
__________________________________________________________________________________________________
separable_conv2d_11 (SeparableC (None, 64, 64, 128)  17664       activation_10[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 64, 64, 128)  0           separable_conv2d_11[0][0]        
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_11[0][0]              
__________________________________________________________________________________________________
separable_conv2d_12 (SeparableC (None, 32, 32, 256)  34176       max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 256)  0           separable_conv2d_12[0][0]        
__________________________________________________________________________________________________
separable_conv2d_13 (SeparableC (None, 32, 32, 256)  68096       activation_12[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 256)  0           separable_conv2d_13[0][0]        
__________________________________________________________________________________________________
separable_conv2d_14 (SeparableC (None, 32, 32, 256)  68096       activation_13[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 256)  0           separable_conv2d_14[0][0]        
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_14[0][0]              
__________________________________________________________________________________________________
separable_conv2d_15 (SeparableC (None, 16, 16, 512)  133888      max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 512)  0           separable_conv2d_15[0][0]        
__________________________________________________________________________________________________
separable_conv2d_16 (SeparableC (None, 16, 16, 512)  267264      activation_15[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 512)  0           separable_conv2d_16[0][0]        
__________________________________________________________________________________________________
separable_conv2d_17 (SeparableC (None, 16, 16, 512)  267264      activation_16[0][0]              
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 512)  0           separable_conv2d_17[0][0]        
__________________________________________________________________________________________________
conv2d_transpose (Conv2DTranspo (None, 32, 32, 256)  1179904     activation_17[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 32, 32, 512)  0           conv2d_transpose[0][0]           
                                                                 activation_14[0][0]              
__________________________________________________________________________________________________
separable_conv2d_18 (SeparableC (None, 32, 32, 128)  70272       concatenate[0][0]                
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 128)  0           separable_conv2d_18[0][0]        
__________________________________________________________________________________________________
separable_conv2d_19 (SeparableC (None, 32, 32, 128)  17664       activation_18[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 128)  0           separable_conv2d_19[0][0]        
__________________________________________________________________________________________________
separable_conv2d_20 (SeparableC (None, 32, 32, 128)  17664       activation_19[0][0]              
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 128)  0           separable_conv2d_20[0][0]        
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 128)  147584      activation_20[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_1[0][0]         
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
separable_conv2d_21 (SeparableC (None, 64, 64, 128)  35200       concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 64, 64, 128)  0           separable_conv2d_21[0][0]        
__________________________________________________________________________________________________
separable_conv2d_22 (SeparableC (None, 64, 64, 128)  17664       activation_21[0][0]              
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 64, 64, 128)  0           separable_conv2d_22[0][0]        
__________________________________________________________________________________________________
separable_conv2d_23 (SeparableC (None, 64, 64, 128)  17664       activation_22[0][0]              
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 64, 64, 128)  0           separable_conv2d_23[0][0]        
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 64) 73792       activation_23[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_2[0][0]         
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
separable_conv2d_24 (SeparableC (None, 128, 128, 64) 9408        concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 128, 128, 64) 0           separable_conv2d_24[0][0]        
__________________________________________________________________________________________________
separable_conv2d_25 (SeparableC (None, 128, 128, 64) 4736        activation_24[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 128, 128, 64) 0           separable_conv2d_25[0][0]        
__________________________________________________________________________________________________
separable_conv2d_26 (SeparableC (None, 128, 128, 64) 4736        activation_25[0][0]              
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 128, 128, 64) 0           separable_conv2d_26[0][0]        
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 32) 18464       activation_26[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_3[0][0]         
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
separable_conv2d_27 (SeparableC (None, 256, 256, 32) 2656        concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 256, 256, 32) 0           separable_conv2d_27[0][0]        
__________________________________________________________________________________________________
separable_conv2d_28 (SeparableC (None, 256, 256, 32) 1344        activation_27[0][0]              
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 256, 256, 32) 0           separable_conv2d_28[0][0]        
__________________________________________________________________________________________________
separable_conv2d_29 (SeparableC (None, 256, 256, 32) 1344        activation_28[0][0]              
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 256, 256, 32) 0           separable_conv2d_29[0][0]        
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 512, 512, 16) 4624        activation_29[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 512, 512, 32) 0           conv2d_transpose_4[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
separable_conv2d_30 (SeparableC (None, 512, 512, 16) 816         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512, 512, 16) 0           separable_conv2d_30[0][0]        
__________________________________________________________________________________________________
separable_conv2d_31 (SeparableC (None, 512, 512, 16) 416         activation_30[0][0]              
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 512, 512, 16) 0           separable_conv2d_31[0][0]        
__________________________________________________________________________________________________
separable_conv2d_32 (SeparableC (None, 512, 512, 16) 416         activation_31[0][0]              
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 512, 512, 16) 0           separable_conv2d_32[0][0]        
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 512, 512, 3)  51          activation_32[0][0]              
==================================================================================================
Total params: 2,525,598
Trainable params: 2,525,598
Non-trainable params: 0
__________________________________________________________________________________________________
None
SHOWING AN IMAGE:
SHOWING A MASK:
2021-04-06 11:29:39.758369: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-06 11:29:39.780528: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2999955000 Hz
Epoch 1/100
36/36 [==============================] - 341s 9s/step - loss: 0.6638 - accuracy: 0.1040 - val_loss: 0.6360 - val_accuracy: 0.1848

Epoch 00001: val_loss improved from inf to 0.63600, saving model to model-proba4-2.h5
Epoch 2/100
36/36 [==============================] - 313s 9s/step - loss: 0.6528 - accuracy: 0.2015 - val_loss: 0.6329 - val_accuracy: 0.4126

Epoch 00002: val_loss improved from 0.63600 to 0.63295, saving model to model-proba4-2.h5
Epoch 3/100
36/36 [==============================] - 313s 9s/step - loss: 0.6413 - accuracy: 0.4665 - val_loss: 0.6323 - val_accuracy: 0.0745

Epoch 00003: val_loss improved from 0.63295 to 0.63225, saving model to model-proba4-2.h5
Epoch 4/100
36/36 [==============================] - 311s 9s/step - loss: 0.6384 - accuracy: 0.2173 - val_loss: 0.6337 - val_accuracy: 0.1011

Epoch 00004: val_loss did not improve from 0.63225
Epoch 5/100
36/36 [==============================] - 320s 9s/step - loss: 0.6401 - accuracy: 0.2104 - val_loss: 0.6344 - val_accuracy: 0.4550

Epoch 00005: val_loss did not improve from 0.63225
Epoch 6/100
36/36 [==============================] - 328s 9s/step - loss: 0.6379 - accuracy: 0.2687 - val_loss: 0.6288 - val_accuracy: 0.0495

Epoch 00006: val_loss improved from 0.63225 to 0.62882, saving model to model-proba4-2.h5
Epoch 7/100
36/36 [==============================] - 313s 9s/step - loss: 0.6355 - accuracy: 0.1185 - val_loss: 0.6286 - val_accuracy: 0.1535

Epoch 00007: val_loss improved from 0.62882 to 0.62859, saving model to model-proba4-2.h5
Epoch 8/100
36/36 [==============================] - 318s 9s/step - loss: 0.6378 - accuracy: 0.1839 - val_loss: 0.6326 - val_accuracy: 0.2889

Epoch 00008: val_loss did not improve from 0.62859
Epoch 9/100
36/36 [==============================] - 327s 9s/step - loss: 0.6399 - accuracy: 0.1573 - val_loss: 0.6253 - val_accuracy: 0.1017

Epoch 00009: val_loss improved from 0.62859 to 0.62530, saving model to model-proba4-2.h5
Epoch 10/100
36/36 [==============================] - 321s 9s/step - loss: 0.6355 - accuracy: 0.1733 - val_loss: 0.6272 - val_accuracy: 0.0732

Epoch 00010: val_loss did not improve from 0.62530
Epoch 11/100
36/36 [==============================] - 315s 9s/step - loss: 0.6327 - accuracy: 0.1755 - val_loss: 0.6257 - val_accuracy: 0.1189

Epoch 00011: val_loss did not improve from 0.62530
Epoch 12/100
36/36 [==============================] - 313s 9s/step - loss: 0.6253 - accuracy: 0.1631 - val_loss: 0.6251 - val_accuracy: 0.1884

Epoch 00012: val_loss improved from 0.62530 to 0.62513, saving model to model-proba4-2.h5
Epoch 13/100
36/36 [==============================] - 303s 8s/step - loss: 0.6293 - accuracy: 0.1457 - val_loss: 0.6337 - val_accuracy: 0.0813

Epoch 00013: val_loss did not improve from 0.62513
Epoch 14/100
36/36 [==============================] - 327s 9s/step - loss: 0.6341 - accuracy: 0.1770 - val_loss: 0.6236 - val_accuracy: 0.1237

Epoch 00014: val_loss improved from 0.62513 to 0.62365, saving model to model-proba4-2.h5
Epoch 15/100
36/36 [==============================] - 314s 9s/step - loss: 0.6294 - accuracy: 0.1521 - val_loss: 0.6319 - val_accuracy: 0.1159

Epoch 00015: val_loss did not improve from 0.62365
Epoch 16/100
36/36 [==============================] - 315s 9s/step - loss: 0.6330 - accuracy: 0.1595 - val_loss: 0.6220 - val_accuracy: 0.1649

Epoch 00016: val_loss improved from 0.62365 to 0.62195, saving model to model-proba4-2.h5
Epoch 17/100
36/36 [==============================] - 310s 8s/step - loss: 0.6255 - accuracy: 0.1825 - val_loss: 0.6482 - val_accuracy: 0.1387

Epoch 00017: val_loss did not improve from 0.62195
Epoch 18/100
36/36 [==============================] - 335s 9s/step - loss: 0.6375 - accuracy: 0.1593 - val_loss: 0.6184 - val_accuracy: 0.2053

Epoch 00018: val_loss improved from 0.62195 to 0.61843, saving model to model-proba4-2.h5
Epoch 19/100
36/36 [==============================] - 309s 9s/step - loss: 0.6289 - accuracy: 0.1937 - val_loss: 0.6254 - val_accuracy: 0.2552

Epoch 00019: val_loss did not improve from 0.61843
Epoch 20/100
36/36 [==============================] - 318s 9s/step - loss: 0.6265 - accuracy: 0.2091 - val_loss: 0.6176 - val_accuracy: 0.2274

Epoch 00020: val_loss improved from 0.61843 to 0.61764, saving model to model-proba4-2.h5
Epoch 21/100
36/36 [==============================] - 306s 8s/step - loss: 0.6239 - accuracy: 0.2589 - val_loss: 0.6202 - val_accuracy: 0.4823

Epoch 00021: val_loss did not improve from 0.61764
Epoch 22/100
36/36 [==============================] - 309s 9s/step - loss: 0.6257 - accuracy: 0.2923 - val_loss: 0.6216 - val_accuracy: 0.3034

Epoch 00022: val_loss did not improve from 0.61764
Epoch 23/100
36/36 [==============================] - 309s 9s/step - loss: 0.6260 - accuracy: 0.2359 - val_loss: 0.6227 - val_accuracy: 0.2781

Epoch 00023: val_loss did not improve from 0.61764
Epoch 24/100
36/36 [==============================] - 315s 9s/step - loss: 0.6327 - accuracy: 0.2418 - val_loss: 0.6207 - val_accuracy: 0.5031

Epoch 00024: val_loss did not improve from 0.61764
Epoch 25/100
36/36 [==============================] - 301s 8s/step - loss: 0.6300 - accuracy: 0.3538 - val_loss: 0.6219 - val_accuracy: 0.2437

Epoch 00025: val_loss did not improve from 0.61764
Epoch 26/100
36/36 [==============================] - 316s 9s/step - loss: 0.6318 - accuracy: 0.2512 - val_loss: 0.6139 - val_accuracy: 0.1208

Epoch 00026: val_loss improved from 0.61764 to 0.61385, saving model to model-proba4-2.h5
Epoch 27/100
36/36 [==============================] - 319s 9s/step - loss: 0.6279 - accuracy: 0.2336 - val_loss: 0.6266 - val_accuracy: 0.1301

Epoch 00027: val_loss did not improve from 0.61385
Epoch 28/100
36/36 [==============================] - 324s 9s/step - loss: 0.6248 - accuracy: 0.2316 - val_loss: 0.6543 - val_accuracy: 0.3557

Epoch 00028: val_loss did not improve from 0.61385
Epoch 29/100
36/36 [==============================] - 318s 9s/step - loss: 0.6219 - accuracy: 0.3506 - val_loss: 0.6258 - val_accuracy: 0.3499

Epoch 00029: val_loss did not improve from 0.61385
Epoch 30/100
36/36 [==============================] - 316s 9s/step - loss: 0.6214 - accuracy: 0.2753 - val_loss: 0.6155 - val_accuracy: 0.2116

Epoch 00030: val_loss did not improve from 0.61385
Epoch 31/100
36/36 [==============================] - 311s 8s/step - loss: 0.6280 - accuracy: 0.2924 - val_loss: 0.6195 - val_accuracy: 0.2466

Epoch 00031: val_loss did not improve from 0.61385
Epoch 32/100
36/36 [==============================] - 315s 9s/step - loss: 0.6211 - accuracy: 0.2870 - val_loss: 0.6158 - val_accuracy: 0.2913

Epoch 00032: val_loss did not improve from 0.61385
Epoch 33/100
36/36 [==============================] - 305s 8s/step - loss: 0.6286 - accuracy: 0.3253 - val_loss: 0.6205 - val_accuracy: 0.2745

Epoch 00033: val_loss did not improve from 0.61385
Epoch 34/100
36/36 [==============================] - 311s 9s/step - loss: 0.6265 - accuracy: 0.2709 - val_loss: 0.6173 - val_accuracy: 0.2362

Epoch 00034: val_loss did not improve from 0.61385
Epoch 35/100
36/36 [==============================] - 323s 9s/step - loss: 0.6249 - accuracy: 0.2648 - val_loss: 0.6199 - val_accuracy: 0.3296

Epoch 00035: val_loss did not improve from 0.61385
Epoch 36/100
36/36 [==============================] - 325s 9s/step - loss: 0.6241 - accuracy: 0.2967 - val_loss: 0.6141 - val_accuracy: 0.1945

Epoch 00036: val_loss did not improve from 0.61385
Epoch 37/100
36/36 [==============================] - 312s 9s/step - loss: 0.6265 - accuracy: 0.2925 - val_loss: 0.6177 - val_accuracy: 0.3505

Epoch 00037: val_loss did not improve from 0.61385
Epoch 38/100
36/36 [==============================] - 315s 9s/step - loss: 0.6227 - accuracy: 0.2877 - val_loss: 0.6169 - val_accuracy: 0.2615

Epoch 00038: val_loss did not improve from 0.61385
Epoch 39/100
36/36 [==============================] - 329s 9s/step - loss: 0.6250 - accuracy: 0.2758 - val_loss: 0.6158 - val_accuracy: 0.2763

Epoch 00039: val_loss did not improve from 0.61385
Epoch 40/100
36/36 [==============================] - 301s 8s/step - loss: 0.6197 - accuracy: 0.3015 - val_loss: 0.6178 - val_accuracy: 0.3399

Epoch 00040: val_loss did not improve from 0.61385
Epoch 41/100
36/36 [==============================] - 320s 9s/step - loss: 0.6223 - accuracy: 0.3043 - val_loss: 0.6239 - val_accuracy: 0.3449

Epoch 00041: val_loss did not improve from 0.61385
Epoch 42/100
36/36 [==============================] - 309s 9s/step - loss: 0.6256 - accuracy: 0.3462 - val_loss: 0.6173 - val_accuracy: 0.1925

Epoch 00042: val_loss did not improve from 0.61385
Epoch 43/100
36/36 [==============================] - 323s 9s/step - loss: 0.6162 - accuracy: 0.2692 - val_loss: 0.6188 - val_accuracy: 0.4512

Epoch 00043: val_loss did not improve from 0.61385
Epoch 44/100
36/36 [==============================] - 308s 9s/step - loss: 0.6312 - accuracy: 0.3714 - val_loss: 0.6149 - val_accuracy: 0.1832

Epoch 00044: val_loss did not improve from 0.61385
Epoch 45/100
36/36 [==============================] - 327s 9s/step - loss: 0.6226 - accuracy: 0.2917 - val_loss: 0.6165 - val_accuracy: 0.1664

Epoch 00045: val_loss did not improve from 0.61385
Epoch 46/100
36/36 [==============================] - 329s 9s/step - loss: 0.6308 - accuracy: 0.2612 - val_loss: 0.6193 - val_accuracy: 0.1502

Epoch 00046: val_loss did not improve from 0.61385
Epoch 47/100
36/36 [==============================] - 308s 9s/step - loss: 0.6198 - accuracy: 0.2611 - val_loss: 0.6191 - val_accuracy: 0.1975

Epoch 00047: val_loss did not improve from 0.61385
Epoch 48/100
36/36 [==============================] - 323s 9s/step - loss: 0.6191 - accuracy: 0.3283 - val_loss: 0.6200 - val_accuracy: 0.4589

Epoch 00048: val_loss did not improve from 0.61385
Epoch 49/100
36/36 [==============================] - 316s 9s/step - loss: 0.6219 - accuracy: 0.3748 - val_loss: 0.6221 - val_accuracy: 0.1622

Epoch 00049: val_loss did not improve from 0.61385
Epoch 50/100
36/36 [==============================] - 309s 9s/step - loss: 0.6228 - accuracy: 0.2881 - val_loss: 0.6131 - val_accuracy: 0.1959

Epoch 00050: val_loss improved from 0.61385 to 0.61310, saving model to model-proba4-2.h5
Epoch 51/100
36/36 [==============================] - 312s 9s/step - loss: 0.6237 - accuracy: 0.3395 - val_loss: 0.6164 - val_accuracy: 0.2568

Epoch 00051: val_loss did not improve from 0.61310
Epoch 52/100
36/36 [==============================] - 319s 9s/step - loss: 0.6237 - accuracy: 0.3326 - val_loss: 0.6251 - val_accuracy: 0.2385

Epoch 00052: val_loss did not improve from 0.61310
Epoch 53/100
36/36 [==============================] - 319s 9s/step - loss: 0.6208 - accuracy: 0.2559 - val_loss: 0.6406 - val_accuracy: 0.2957

Epoch 00053: val_loss did not improve from 0.61310
Epoch 54/100
36/36 [==============================] - 326s 9s/step - loss: 0.6213 - accuracy: 0.3306 - val_loss: 0.6159 - val_accuracy: 0.1622

Epoch 00054: val_loss did not improve from 0.61310
Epoch 55/100
36/36 [==============================] - 319s 9s/step - loss: 0.6189 - accuracy: 0.2248 - val_loss: 0.6066 - val_accuracy: 0.2012

Epoch 00055: val_loss improved from 0.61310 to 0.60664, saving model to model-proba4-2.h5
Epoch 56/100
36/36 [==============================] - 314s 9s/step - loss: 0.6237 - accuracy: 0.3012 - val_loss: 0.6209 - val_accuracy: 0.2642

Epoch 00056: val_loss did not improve from 0.60664
Epoch 57/100
36/36 [==============================] - 324s 9s/step - loss: 0.6197 - accuracy: 0.2742 - val_loss: 0.6269 - val_accuracy: 0.2850

Epoch 00057: val_loss did not improve from 0.60664
Epoch 58/100
36/36 [==============================] - 307s 9s/step - loss: 0.6236 - accuracy: 0.3595 - val_loss: 0.6167 - val_accuracy: 0.2676

Epoch 00058: val_loss did not improve from 0.60664
Epoch 59/100
36/36 [==============================] - 315s 9s/step - loss: 0.6189 - accuracy: 0.3828 - val_loss: 0.6093 - val_accuracy: 0.2067

Epoch 00059: val_loss did not improve from 0.60664
Epoch 60/100
36/36 [==============================] - 312s 9s/step - loss: 0.6197 - accuracy: 0.3951 - val_loss: 0.6123 - val_accuracy: 0.2661

Epoch 00060: val_loss did not improve from 0.60664
Epoch 61/100
36/36 [==============================] - 313s 9s/step - loss: 0.6180 - accuracy: 0.3313 - val_loss: 0.6057 - val_accuracy: 0.6344

Epoch 00061: val_loss improved from 0.60664 to 0.60569, saving model to model-proba4-2.h5
Epoch 62/100
36/36 [==============================] - 305s 8s/step - loss: 0.6224 - accuracy: 0.3028 - val_loss: 0.6091 - val_accuracy: 0.3114

Epoch 00062: val_loss did not improve from 0.60569
Epoch 63/100
36/36 [==============================] - 319s 9s/step - loss: 0.6203 - accuracy: 0.3092 - val_loss: 0.6137 - val_accuracy: 0.1935

Epoch 00063: val_loss did not improve from 0.60569
Epoch 64/100
36/36 [==============================] - 318s 9s/step - loss: 0.6178 - accuracy: 0.2784 - val_loss: 0.6108 - val_accuracy: 0.3554

Epoch 00064: val_loss did not improve from 0.60569
Epoch 65/100
36/36 [==============================] - 323s 9s/step - loss: 0.6192 - accuracy: 0.3134 - val_loss: 0.6124 - val_accuracy: 0.2337

Epoch 00065: val_loss did not improve from 0.60569
Epoch 66/100
36/36 [==============================] - 313s 9s/step - loss: 0.6248 - accuracy: 0.3014 - val_loss: 0.6198 - val_accuracy: 0.4566

Epoch 00066: val_loss did not improve from 0.60569
Epoch 67/100
36/36 [==============================] - 315s 9s/step - loss: 0.6148 - accuracy: 0.3383 - val_loss: 0.6121 - val_accuracy: 0.2057

Epoch 00067: val_loss did not improve from 0.60569
Epoch 68/100
36/36 [==============================] - 305s 8s/step - loss: 0.6213 - accuracy: 0.3166 - val_loss: 0.6046 - val_accuracy: 0.2404

Epoch 00068: val_loss improved from 0.60569 to 0.60455, saving model to model-proba4-2.h5
Epoch 69/100
36/36 [==============================] - 302s 8s/step - loss: 0.6227 - accuracy: 0.3616 - val_loss: 0.6127 - val_accuracy: 0.4439

Epoch 00069: val_loss did not improve from 0.60455
Epoch 70/100
36/36 [==============================] - 307s 8s/step - loss: 0.6194 - accuracy: 0.2765 - val_loss: 0.6129 - val_accuracy: 0.1205

Epoch 00070: val_loss did not improve from 0.60455
Epoch 71/100
36/36 [==============================] - 320s 9s/step - loss: 0.6221 - accuracy: 0.2475 - val_loss: 0.6132 - val_accuracy: 0.2326

Epoch 00071: val_loss did not improve from 0.60455
Epoch 72/100
36/36 [==============================] - 315s 9s/step - loss: 0.6252 - accuracy: 0.2898 - val_loss: 0.6182 - val_accuracy: 0.3498

Epoch 00072: val_loss did not improve from 0.60455
Epoch 73/100
36/36 [==============================] - 319s 9s/step - loss: 0.6203 - accuracy: 0.3112 - val_loss: 0.6133 - val_accuracy: 0.3897

Epoch 00073: val_loss did not improve from 0.60455
Epoch 74/100
36/36 [==============================] - 289s 8s/step - loss: 0.6142 - accuracy: 0.3162 - val_loss: 0.6094 - val_accuracy: 0.2085

Epoch 00074: val_loss did not improve from 0.60455
Epoch 75/100
36/36 [==============================] - 311s 9s/step - loss: 0.6204 - accuracy: 0.2816 - val_loss: 0.6149 - val_accuracy: 0.4190

Epoch 00075: val_loss did not improve from 0.60455
Epoch 76/100
36/36 [==============================] - 304s 8s/step - loss: 0.6196 - accuracy: 0.2792 - val_loss: 0.6250 - val_accuracy: 0.2366

Epoch 00076: val_loss did not improve from 0.60455
Epoch 77/100
36/36 [==============================] - 322s 9s/step - loss: 0.6241 - accuracy: 0.2942 - val_loss: 0.6207 - val_accuracy: 0.1818

Epoch 00077: val_loss did not improve from 0.60455
Epoch 78/100
36/36 [==============================] - 318s 9s/step - loss: 0.6350 - accuracy: 0.2385 - val_loss: 0.6175 - val_accuracy: 0.3040

Epoch 00078: val_loss did not improve from 0.60455
Epoch 79/100
36/36 [==============================] - 312s 9s/step - loss: 0.6117 - accuracy: 0.2837 - val_loss: 0.6117 - val_accuracy: 0.4518

Epoch 00079: val_loss did not improve from 0.60455
Epoch 80/100
36/36 [==============================] - 338s 9s/step - loss: 0.6176 - accuracy: 0.3798 - val_loss: 0.6088 - val_accuracy: 0.3257

Epoch 00080: val_loss did not improve from 0.60455
Epoch 81/100
36/36 [==============================] - 309s 9s/step - loss: 0.6167 - accuracy: 0.3412 - val_loss: 0.6076 - val_accuracy: 0.3041

Epoch 00081: val_loss did not improve from 0.60455
Epoch 82/100
36/36 [==============================] - 328s 9s/step - loss: 0.6143 - accuracy: 0.4058 - val_loss: 0.6302 - val_accuracy: 0.2885

Epoch 00082: val_loss did not improve from 0.60455
Epoch 83/100
36/36 [==============================] - 319s 9s/step - loss: 0.6172 - accuracy: 0.3176 - val_loss: 0.6111 - val_accuracy: 0.1933

Epoch 00083: val_loss did not improve from 0.60455
Epoch 84/100
36/36 [==============================] - 319s 9s/step - loss: 0.6155 - accuracy: 0.2771 - val_loss: 0.6356 - val_accuracy: 0.3939

Epoch 00084: val_loss did not improve from 0.60455
Epoch 85/100
36/36 [==============================] - 321s 9s/step - loss: 0.6179 - accuracy: 0.3258 - val_loss: 0.6096 - val_accuracy: 0.2289

Epoch 00085: val_loss did not improve from 0.60455
Epoch 86/100
36/36 [==============================] - 313s 9s/step - loss: 0.6162 - accuracy: 0.3682 - val_loss: 0.6050 - val_accuracy: 0.1808

Epoch 00086: val_loss did not improve from 0.60455
Epoch 87/100
36/36 [==============================] - 309s 9s/step - loss: 0.6199 - accuracy: 0.2546 - val_loss: 0.6121 - val_accuracy: 0.3283

Epoch 00087: val_loss did not improve from 0.60455
Epoch 88/100
36/36 [==============================] - 317s 9s/step - loss: 0.6159 - accuracy: 0.2969 - val_loss: 0.6087 - val_accuracy: 0.2528

Epoch 00088: val_loss did not improve from 0.60455
Epoch 89/100
36/36 [==============================] - 320s 9s/step - loss: 0.6231 - accuracy: 0.3273 - val_loss: 0.6051 - val_accuracy: 0.2741

Epoch 00089: val_loss did not improve from 0.60455
Epoch 90/100
36/36 [==============================] - 323s 9s/step - loss: 0.6129 - accuracy: 0.2867 - val_loss: 0.6093 - val_accuracy: 0.4041

Epoch 00090: val_loss did not improve from 0.60455
Epoch 91/100
36/36 [==============================] - 329s 9s/step - loss: 0.6145 - accuracy: 0.3501 - val_loss: 0.6193 - val_accuracy: 0.1678

Epoch 00091: val_loss did not improve from 0.60455
Epoch 92/100
36/36 [==============================] - 318s 9s/step - loss: 0.6135 - accuracy: 0.2478 - val_loss: 0.6126 - val_accuracy: 0.2757

Epoch 00092: val_loss did not improve from 0.60455
Epoch 93/100
36/36 [==============================] - 311s 9s/step - loss: 0.6165 - accuracy: 0.2768 - val_loss: 0.6115 - val_accuracy: 0.1976

Epoch 00093: val_loss did not improve from 0.60455
Epoch 94/100
36/36 [==============================] - 328s 9s/step - loss: 0.6081 - accuracy: 0.2943 - val_loss: 0.6153 - val_accuracy: 0.3927

Epoch 00094: val_loss did not improve from 0.60455
Epoch 95/100
36/36 [==============================] - 318s 9s/step - loss: 0.6154 - accuracy: 0.3609 - val_loss: 0.6066 - val_accuracy: 0.2575

Epoch 00095: val_loss did not improve from 0.60455
Epoch 96/100
36/36 [==============================] - 322s 9s/step - loss: 0.6188 - accuracy: 0.3343 - val_loss: 0.6119 - val_accuracy: 0.2072

Epoch 00096: val_loss did not improve from 0.60455
Epoch 97/100
36/36 [==============================] - 330s 9s/step - loss: 0.6181 - accuracy: 0.2466 - val_loss: 0.6137 - val_accuracy: 0.5040

Epoch 00097: val_loss did not improve from 0.60455
Epoch 98/100
36/36 [==============================] - 319s 9s/step - loss: 0.6090 - accuracy: 0.3757 - val_loss: 0.6100 - val_accuracy: 0.2787

Epoch 00098: val_loss did not improve from 0.60455
Epoch 99/100
36/36 [==============================] - 316s 9s/step - loss: 0.6087 - accuracy: 0.3351 - val_loss: 0.6118 - val_accuracy: 0.4947

Epoch 00099: val_loss did not improve from 0.60455
Epoch 100/100
36/36 [==============================] - 319s 9s/step - loss: 0.6134 - accuracy: 0.4244 - val_loss: 0.6153 - val_accuracy: 0.3228

Epoch 00100: val_loss did not improve from 0.60455
veronika@kamis-nn01:~/radiIzvanka_QAApproved/probe$ 
